{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/osvaldohernandez/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import mmcv\n",
    "from mmdet3d.apis import init_model, inference_detector\n",
    "import torch\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "from math import cos, sin\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Loading\n",
    "In this section, three main datasets are loaded:\n",
    "- df_images: Contains the image data for object detection, including file paths for image_id, image_name, and corresponding metadata.\n",
    "- df_labels: Contains the ground truth labels for object detection, including object_class, bounding_box_coordinates, and image_id.\n",
    "- df_calibration: Includes calibration parameters such as camera matrix, distortion coefficients, and extrinsic parameters for aligning image and sensor data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path  = \"./data/kitti/training/image_2/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all image files\n",
    "image_files = os.listdir(image_path)\n",
    "\n",
    "# Create a DataFrame to store image file paths\n",
    "df_images = pd.DataFrame({\n",
    "    'image_id': range(len(image_files)),\n",
    "    'image_name': image_files,\n",
    "    'file_path': [os.path.join(image_path, img) for img in image_files]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   image_id  image_name                                 file_path\n",
      "0         0  004863.png  ./data/kitti/training/image_2/004863.png\n",
      "1         1  006912.png  ./data/kitti/training/image_2/006912.png\n",
      "2         2  006906.png  ./data/kitti/training/image_2/006906.png\n",
      "3         3  004877.png  ./data/kitti/training/image_2/004877.png\n",
      "4         4  005599.png  ./data/kitti/training/image_2/005599.png\n"
     ]
    }
   ],
   "source": [
    "# Print the first few entries of df_images\n",
    "print(df_images.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  image_id object_class bounding_box_coordinates\n",
      "0   006145          Car     (595, 177, 637, 217)\n",
      "1   006145          Car       (0, 185, 198, 277)\n",
      "2   006145          Car    (812, 169, 1023, 293)\n",
      "3   006145          Car     (764, 172, 947, 261)\n",
      "4   006145          Car     (708, 177, 852, 243)\n"
     ]
    }
   ],
   "source": [
    "# Define the path to your KITTI dataset labels\n",
    "label_path = \"./data/kitti/training/label_2/\"\n",
    "\n",
    "# Function to load and parse a label file\n",
    "def load_labels(label_file):\n",
    "    labels = []\n",
    "    with open(label_file, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            obj_class = parts[0]\n",
    "            x_min = int(float(parts[4]))\n",
    "            y_min = int(float(parts[5]))\n",
    "            x_max = int(float(parts[6]))\n",
    "            y_max = int(float(parts[7]))\n",
    "            labels.append({'object_class': obj_class, 'bounding_box': (x_min, y_min, x_max, y_max)})\n",
    "    return labels\n",
    "\n",
    "# List all label files and accumulate label data\n",
    "label_files = os.listdir(label_path)\n",
    "label_data = []\n",
    "\n",
    "for label_file in label_files:\n",
    "    file_path = os.path.join(label_path, label_file)\n",
    "    \n",
    "    # Use the filename without the extension as the image_id (e.g., '000001')\n",
    "    image_id = os.path.splitext(label_file)[0]\n",
    "    \n",
    "    labels = load_labels(file_path)\n",
    "    for label in labels:\n",
    "        label_data.append({\n",
    "            'image_id': image_id,  # Use image_id derived from the filename\n",
    "            'object_class': label['object_class'],\n",
    "            'bounding_box_coordinates': label['bounding_box']\n",
    "        })\n",
    "\n",
    "# Create a DataFrame using pd.concat\n",
    "df_labels = pd.DataFrame(label_data)\n",
    "\n",
    "# Print the first few entries of df_labels\n",
    "print(df_labels.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   image_id object_class bounding_box_coordinates\n",
      "0    006145          Car     (595, 177, 637, 217)\n",
      "1    006145          Car       (0, 185, 198, 277)\n",
      "2    006145          Car    (812, 169, 1023, 293)\n",
      "3    006145          Car     (764, 172, 947, 261)\n",
      "4    006145          Car     (708, 177, 852, 243)\n",
      "..      ...          ...                      ...\n",
      "95   003997   Pedestrian        (0, 152, 88, 336)\n",
      "96   003997     DontCare        (0, 159, 93, 349)\n",
      "97   004020          Car     (600, 177, 657, 229)\n",
      "98   004020          Car     (585, 178, 606, 192)\n",
      "99   004020     DontCare     (718, 171, 726, 178)\n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Check that bounding_box_coordinates are unique per object\n",
    "print(df_labels.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   image_id                                   calibration_data\n",
      "0         0  {'P0': [721.5377, 0.0, 609.5593, 0.0, 0.0, 721...\n",
      "1         1  {'P0': [721.5377, 0.0, 609.5593, 0.0, 0.0, 721...\n",
      "2         2  {'P0': [721.5377, 0.0, 609.5593, 0.0, 0.0, 721...\n",
      "3         3  {'P0': [721.5377, 0.0, 609.5593, 0.0, 0.0, 721...\n",
      "4         4  {'P0': [721.5377, 0.0, 609.5593, 0.0, 0.0, 721...\n"
     ]
    }
   ],
   "source": [
    "# Define the path to your KITTI dataset calibration files\n",
    "calibration_path = \"./data/kitti/training/calib/\"\n",
    "\n",
    "# Function to load calibration parameters\n",
    "def load_calibration(calib_file):\n",
    "    calib_data = {}\n",
    "    with open(calib_file, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            \n",
    "            # Skip empty lines or comments\n",
    "            if not line:\n",
    "                continue\n",
    "\n",
    "            # Check if the line has the expected ':' delimiter\n",
    "            if ':' in line:\n",
    "                key, value = line.split(':', 1)\n",
    "                calib_data[key.strip()] = [float(x) for x in value.strip().split()]\n",
    "            else:\n",
    "                print(f\"Skipping malformed line: {line}\")\n",
    "    \n",
    "    return calib_data\n",
    "\n",
    "# List all calibration files and accumulate calibration data\n",
    "calibration_files = os.listdir(calibration_path)\n",
    "calibration_data = []\n",
    "\n",
    "for i, calib_file in enumerate(calibration_files):\n",
    "    file_path = os.path.join(calibration_path, calib_file)\n",
    "    calib_data = load_calibration(file_path)\n",
    "    calibration_data.append({\n",
    "        'image_id': i,\n",
    "        'calibration_data': calib_data\n",
    "    })\n",
    "\n",
    "# Create a DataFrame using pd.concat\n",
    "df_calibration = pd.DataFrame(calibration_data)\n",
    "\n",
    "# Print the first few entries of df_calibration\n",
    "print(df_calibration.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the shape of each DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images DataFrame shape: (7481, 3)\n",
      "Labels DataFrame shape: (51865, 3)\n",
      "Calibration DataFrame shape: (7481, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Images DataFrame shape:\", df_images.shape)\n",
    "print(\"Labels DataFrame shape:\", df_labels.shape)\n",
    "print(\"Calibration DataFrame shape:\", df_calibration.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for missing values in each DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in Images DataFrame:\n",
      " image_id      0\n",
      "image_name    0\n",
      "file_path     0\n",
      "dtype: int64\n",
      "Missing values in Labels DataFrame:\n",
      " image_id                    0\n",
      "object_class                0\n",
      "bounding_box_coordinates    0\n",
      "dtype: int64\n",
      "Missing values in Calibration DataFrame:\n",
      " image_id            0\n",
      "calibration_data    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing values in Images DataFrame:\\n\", df_images.isna().sum())\n",
    "print(\"Missing values in Labels DataFrame:\\n\", df_labels.isna().sum())\n",
    "print(\"Missing values in Calibration DataFrame:\\n\", df_calibration.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a summary of the data types and basic info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images DataFrame info:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7481 entries, 0 to 7480\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   image_id    7481 non-null   int64 \n",
      " 1   image_name  7481 non-null   object\n",
      " 2   file_path   7481 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 175.5+ KB\n",
      "Labels DataFrame info:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51865 entries, 0 to 51864\n",
      "Data columns (total 3 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   image_id                  51865 non-null  object\n",
      " 1   object_class              51865 non-null  object\n",
      " 2   bounding_box_coordinates  51865 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 1.2+ MB\n",
      "Calibration DataFrame info:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7481 entries, 0 to 7480\n",
      "Data columns (total 2 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   image_id          7481 non-null   int64 \n",
      " 1   calibration_data  7481 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 117.0+ KB\n"
     ]
    }
   ],
   "source": [
    "print(\"Images DataFrame info:\\n\")\n",
    "df_images.info()\n",
    "\n",
    "print(\"Labels DataFrame info:\\n\")\n",
    "df_labels.info()\n",
    "\n",
    "print(\"Calibration DataFrame info:\\n\")\n",
    "df_calibration.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Set the device (GPU or CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define paths for the config and checkpoint files\n",
    "config_file = './configs/pointpillars/pointpillars_hv_secfpn_8xb6-160e_kitti-3d-3class.py'\n",
    "checkpoint_file = './checkpoints/hv_pointpillars_secfpn_6x8_160e_kitti-3d-3class_20220301_150306-37dc2420.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: ./checkpoints/hv_pointpillars_secfpn_6x8_160e_kitti-3d-3class_20220301_150306-37dc2420.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/osvaldohernandez/mmdetection3d/mmdet3d/models/dense_heads/anchor3d_head.py:94: UserWarning: dir_offset and dir_limit_offset will be depressed and be incorporated into box coder in the future\n",
      "  warnings.warn(\n",
      "/Users/osvaldohernandez/mmdetection3d/mmdet3d/apis/inference.py:109: UserWarning: Don't suggest using CPU device. Some functions are not supported for now.\n",
      "  warnings.warn('Don\\'t suggest using CPU device. '\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Initialize the model\n",
    "model = init_model(config_file, checkpoint_file, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Load and visualize the point cloud using Open3D\n",
    "def load_kitti_bin_file(bin_file):\n",
    "    point_cloud = np.fromfile(bin_file, dtype=np.float32).reshape(-1, 4)\n",
    "    print(f\"Loaded point cloud shape: {point_cloud.shape}\")  # Check if the point cloud is loaded correctl\n",
    "    return point_cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Load the LiDAR point cloud sample (replace the path to your point cloud file)\n",
    "pcd_file = './data/kitti/training/velodyne/005137.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/osvaldohernandez/Library/Python/3.9/lib/python/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3527.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Perform inference (object detection)\n",
    "result, _  = inference_detector(model, pcd_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded point cloud shape: (117660, 4)\n"
     ]
    }
   ],
   "source": [
    "# Load the point cloud from the .bin file\n",
    "point_cloud = load_kitti_bin_file(pcd_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the shape of each DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Open3D point cloud format\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(point_cloud[:, :3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected objects in ./data/kitti/training/velodyne/005137.bin:\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Process and display the detected objects\n",
    "class_names = model.dataset_meta['classes']  # Classes for the dataset (e.g., Car, Pedestrian, Cyclist)\n",
    "threshold = 0.5  # Confidence threshold for displaying the detected objects\n",
    "\n",
    "print(f\"Detected objects in {pcd_file}:\")\n",
    "\n",
    "# Convert to Open3D point cloud format\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(point_cloud[:, :3])  # Only use x, y, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to compute the 8 corners of a bounding box\n",
    "def compute_bounding_box_corners(bbox):\n",
    "    # Access the underlying tensor from LiDARInstance3DBoxes\n",
    "    bbox = bbox.tensor.cpu().numpy()  # Convert to numpy array\n",
    "    \n",
    "    # Unpack the individual bounding boxes\n",
    "    all_corners = []\n",
    "    for box in bbox:\n",
    "        x, y, z, dx, dy, dz, heading = box\n",
    "\n",
    "        # Rotation matrix for heading\n",
    "        rot_matrix = np.array([[cos(heading), -sin(heading)], [sin(heading), cos(heading)]])\n",
    "        \n",
    "        # 3D bounding box corners before rotation\n",
    "        corners = np.array([\n",
    "            [-dx / 2, -dy / 2, -dz / 2], [dx / 2, -dy / 2, -dz / 2], \n",
    "            [dx / 2, dy / 2, -dz / 2], [-dx / 2, dy / 2, -dz / 2], \n",
    "            [-dx / 2, -dy / 2, dz / 2], [dx / 2, -dy / 2, dz / 2], \n",
    "            [dx / 2, dy / 2, dz / 2], [-dx / 2, dy / 2, dz / 2]\n",
    "        ])\n",
    "        \n",
    "        # Apply rotation to the x and y dimensions\n",
    "        rotated_corners = np.dot(corners[:, [0, 1]], rot_matrix)\n",
    "        corners[:, 0:2] = rotated_corners\n",
    "        \n",
    "        # Add the center of the box to all the corners to translate it\n",
    "        corners[:, 0] += x\n",
    "        corners[:, 1] += y\n",
    "        corners[:, 2] += z\n",
    "\n",
    "        all_corners.append(corners)\n",
    "\n",
    "    return all_corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to create a 3D bounding box in Open3D\n",
    "def create_bounding_box_lines(bbox):\n",
    "    all_bbox_corners = compute_bounding_box_corners(bbox)  # Get the 8 corners of the 3D bounding box\n",
    "\n",
    "    line_sets = []\n",
    "    for bbox_corners in all_bbox_corners:\n",
    "        # Define the 12 edges of the bounding box\n",
    "        edges = [\n",
    "            [0, 1], [1, 2], [2, 3], [3, 0],  # Bottom face\n",
    "            [4, 5], [5, 6], [6, 7], [7, 4],  # Top face\n",
    "            [0, 4], [1, 5], [2, 6], [3, 7]   # Vertical edges\n",
    "        ]\n",
    "\n",
    "        # Create LineSet object for bounding box\n",
    "        line_set = o3d.geometry.LineSet()\n",
    "        line_set.points = o3d.utility.Vector3dVector(bbox_corners)\n",
    "        line_set.lines = o3d.utility.Vector2iVector(edges)\n",
    "        \n",
    "        # Assign a color to the lines (blue in this case)\n",
    "        line_set.colors = o3d.utility.Vector3dVector([[0, 0, 1] for _ in range(len(edges))])\n",
    "        \n",
    "        line_sets.append(line_set)\n",
    "    \n",
    "    return line_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected Pedestrian with confidence 0.5604645609855652\n",
      "Detected Cyclist with confidence 0.9474270343780518\n",
      "Detected Cyclist with confidence 0.8887242078781128\n",
      "Detected Car with confidence 0.9626887440681458\n",
      "Detected Car with confidence 0.9603883624076843\n",
      "Detected Car with confidence 0.9451578855514526\n",
      "Detected Car with confidence 0.921866774559021\n",
      "Detected Car with confidence 0.809282660484314\n",
      "Detected Car with confidence 0.7989785075187683\n",
      "Detected Car with confidence 0.7863332033157349\n",
      "Detected Car with confidence 0.7257812023162842\n",
      "Detected Car with confidence 0.6600877046585083\n",
      "Detected Car with confidence 0.6276063919067383\n"
     ]
    }
   ],
   "source": [
    " # Prepare bounding boxes for visualization\n",
    "bounding_boxes = []\n",
    "pred_instances = result.pred_instances_3d\n",
    "for i in range(len(pred_instances.bboxes_3d)):\n",
    "    bbox = pred_instances.bboxes_3d[i]  # Get the bounding box tensor\n",
    "    score = pred_instances.scores_3d[i].cpu().numpy()  # Get confidence score\n",
    "    label = pred_instances.labels_3d[i].cpu().numpy()  # Get class label\n",
    "\n",
    "    if score >= threshold:\n",
    "        # Get the class name corresponding to the label\n",
    "        class_name = class_names[label]\n",
    "        \n",
    "        # Print the class name and score\n",
    "        print(f\"Detected {class_name} with confidence {score}\")\n",
    "\n",
    "        # Create and visualize the bounding box lines\n",
    "        bounding_box_lines = create_bounding_box_lines(bbox)  # Create the bounding box lines\n",
    "        bounding_boxes.extend(bounding_box_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-13 20:05:32.391 Python[32863:574244] WARNING: Secure coding is automatically enabled for restorable state! However, not on all supported macOS versions of this application. Opt-in to secure coding explicitly by implementing NSApplicationDelegate.applicationSupportsSecureRestorableState:.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 8: Visualize the point cloud with bounding boxes using Open3D\n",
    "vis = o3d.visualization.Visualizer()\n",
    "vis.create_window()\n",
    "vis.add_geometry(pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Non-blocking visualization\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m----> 7\u001b[0m     \u001b[43mvis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll_events\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     vis\u001b[38;5;241m.\u001b[39mupdate_renderer()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Add all bounding boxes to the visualizer\n",
    "for bbox in bounding_boxes:\n",
    "    vis.add_geometry(bbox)\n",
    "\n",
    "# Non-blocking visualization\n",
    "while True:\n",
    "    vis.poll_events()\n",
    "    vis.update_renderer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation Metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overfitting/Underfitting Analysis\n",
    "\n",
    "Due to the nature of this report, which utilizes a pre-trained model, we do not have access to the training loss metrics. The model has not been retrained in this context, and therefore, we cannot evaluate the training loss or monitor overfitting/underfitting behavior through this metric. If retraining was conducted, tracking training and validation loss over epochs would provide insights into the model's generalization capabilities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision, Recall, and F1-Score\n",
    "\n",
    "Using the ground truth and predicted labels, we calculate precision, recall, and F1-score to evaluate the model's performance in detecting objects accurately.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "velodyne_dir = './data/kitti/training/velodyne/'  # Training point cloud directory\n",
    "label_dir = './data/kitti/training/label_2/'      # Ground truth label directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  image_id object_class      bounding_box confidence_score\n",
      "0   001372            0  (18, -4, 19, -3)       0.78117496\n",
      "1   001372            0    (5, 20, 6, 21)       0.34733957\n",
      "2   001372            0  (47, -4, 48, -3)       0.23190214\n",
      "3   001372            0    (16, 8, 17, 9)       0.22101979\n",
      "4   001372            0  (14, -9, 15, -8)       0.16573866\n",
      "  image_id object_class bounding_box_coordinates\n",
      "0   001372          Car      (91, 191, 369, 323)\n",
      "1   001372      Cyclist     (328, 171, 426, 310)\n",
      "2   001372          Car     (459, 181, 528, 219)\n",
      "3   001372          Car     (660, 174, 707, 212)\n",
      "4   001372          Car     (628, 169, 659, 188)\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Iterate over a subset of point cloud files in the training set and store predictions\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "subset_size = 500  # Define the subset size (e.g., first 100 point clouds)\n",
    "\n",
    "# List all point cloud files in the training directory\n",
    "pointcloud_files = [f for f in os.listdir(velodyne_dir) if f.endswith('.bin')]\n",
    "\n",
    "# Iterate over a subset of the point cloud files\n",
    "for pointcloud_file in pointcloud_files[:subset_size]:\n",
    "    image_id = os.path.splitext(pointcloud_file)[0]  # Get image ID from the filename\n",
    "\n",
    "    # Load the point cloud\n",
    "    pcd_file = os.path.join(velodyne_dir, pointcloud_file)\n",
    "    \n",
    "    # Perform inference\n",
    "    result, _ = inference_detector(model, pcd_file)\n",
    "    \n",
    "    # Store the predictions\n",
    "    pred_instances = result.pred_instances_3d\n",
    "    for i in range(len(pred_instances.bboxes_3d)):\n",
    "        predicted_label = pred_instances.labels_3d[i].cpu().numpy()  # Get predicted class label\n",
    "        score = pred_instances.scores_3d[i].cpu().numpy()  # Get confidence score\n",
    "        bbox = pred_instances.bboxes_3d[i].tensor.cpu().numpy()[0]  # Get bounding box coordinates\n",
    "\n",
    "        # Convert 3D to 2D bounding box (x_min, y_min, x_max, y_max)\n",
    "        x_min = int(bbox[0] - bbox[3] / 2)\n",
    "        y_min = int(bbox[1] - bbox[4] / 2)\n",
    "        x_max = int(bbox[0] + bbox[3] / 2)\n",
    "        y_max = int(bbox[1] + bbox[4] / 2)\n",
    "\n",
    "        all_predictions.append({\n",
    "            'image_id': image_id,\n",
    "            'object_class': predicted_label,\n",
    "            'bounding_box': (x_min, y_min, x_max, y_max),\n",
    "            'confidence_score': score \n",
    "        })\n",
    "    \n",
    "    # Step 6: Load corresponding labels\n",
    "    label_file = os.path.join(label_path, image_id + '.txt')\n",
    "    labels = load_labels(label_file)\n",
    "\n",
    "    # Store the labels with the corresponding image_id\n",
    "    for label in labels:\n",
    "        all_labels.append({\n",
    "            'image_id': image_id,\n",
    "            'object_class': label['object_class'],\n",
    "            'bounding_box_coordinates': label['bounding_box']\n",
    "        })\n",
    "\n",
    "# Step 7: Convert predictions and labels to DataFrames\n",
    "df_predictions_1 = pd.DataFrame(all_predictions)\n",
    "df_labels1 = pd.DataFrame(all_labels)\n",
    "\n",
    "# Step 8: Print the first few entries of predictions and labels\n",
    "print(df_predictions_1.head())\n",
    "print(df_labels1.head())\n",
    "\n",
    "# Step 9: Save the predictions and labels to CSV files for later use\n",
    "df_predictions_1.to_csv('kitti_train_subset_predictions.csv', index=False)\n",
    "df_labels1.to_csv('kitti_train_subset_labels.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image_id                    0\n",
       "object_class                0\n",
       "bounding_box_coordinates    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels1.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Car', 'Cyclist', 'DontCare', 'Pedestrian', 'Van', 'Truck', 'Tram',\n",
       "       'Misc', 'Person_sitting'], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels1['object_class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN values in object_class after mapping: 886\n",
      "[0. 2. 1.]\n",
      "  image_id  object_class bounding_box_coordinates\n",
      "0   001372           0.0      (91, 191, 369, 323)\n",
      "1   001372           2.0     (328, 171, 426, 310)\n",
      "2   001372           0.0     (459, 181, 528, 219)\n",
      "3   001372           0.0     (660, 174, 707, 212)\n",
      "4   001372           0.0     (628, 169, 659, 188)\n"
     ]
    }
   ],
   "source": [
    "# Create a copy of df_labels1 to preserve the original data\n",
    "df_labels2 = df_labels1.copy()\n",
    "\n",
    "class_name_to_label = {\n",
    "    'Car': 0, 'Pedestrian': 1, 'Cyclist': 2, 'Van': 0\n",
    "}\n",
    "\n",
    "# Apply the mapping to ground truth object classes\n",
    "df_labels2['object_class'] = df_labels2['object_class'].map(class_name_to_label)\n",
    "\n",
    "# Check for NaN values in 'object_class' after mapping\n",
    "print(\"Number of NaN values in object_class after mapping:\", df_labels2['object_class'].isna().sum())\n",
    "\n",
    "# Drop rows with NaN values in 'object_class' (these correspond to 'DontCare' or other unmapped classes)\n",
    "df_labels2 = df_labels2.dropna(subset=['object_class'])\n",
    "\n",
    "# Verify that no NaN values remain after dropping\n",
    "print(df_labels2['object_class'].unique())  # Should only show 0, 1, 2 (Car, Pedestrian, Cyclist)\n",
    "print(df_labels2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>object_class</th>\n",
       "      <th>bounding_box_coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001372</td>\n",
       "      <td>Car</td>\n",
       "      <td>(91, 191, 369, 323)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001372</td>\n",
       "      <td>Cyclist</td>\n",
       "      <td>(328, 171, 426, 310)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001372</td>\n",
       "      <td>Car</td>\n",
       "      <td>(459, 181, 528, 219)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001372</td>\n",
       "      <td>Car</td>\n",
       "      <td>(660, 174, 707, 212)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001372</td>\n",
       "      <td>Car</td>\n",
       "      <td>(628, 169, 659, 188)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id object_class bounding_box_coordinates\n",
       "0   001372          Car      (91, 191, 369, 323)\n",
       "1   001372      Cyclist     (328, 171, 426, 310)\n",
       "2   001372          Car     (459, 181, 528, 219)\n",
       "3   001372          Car     (660, 174, 707, 212)\n",
       "4   001372          Car     (628, 169, 659, 188)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image_id                    0\n",
       "object_class                0\n",
       "bounding_box_coordinates    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  image_id  object_class_true    bounding_box_true object_class_pred  \\\n",
      "0   001372                0.0  (91, 191, 369, 323)                 0   \n",
      "1   001372                0.0  (91, 191, 369, 323)                 0   \n",
      "2   001372                0.0  (91, 191, 369, 323)                 0   \n",
      "3   001372                0.0  (91, 191, 369, 323)                 0   \n",
      "4   001372                0.0  (91, 191, 369, 323)                 0   \n",
      "\n",
      "  bounding_box_pred confidence_score  \n",
      "0  (18, -4, 19, -3)       0.78117496  \n",
      "1    (5, 20, 6, 21)       0.34733957  \n",
      "2  (47, -4, 48, -3)       0.23190214  \n",
      "3    (16, 8, 17, 9)       0.22101979  \n",
      "4  (14, -9, 15, -8)       0.16573866  \n"
     ]
    }
   ],
   "source": [
    "# Ensure 'image_id' is a string in both DataFrames\n",
    "df_labels2['image_id'] = df_labels2['image_id'].astype(str)\n",
    "df_predictions_1['image_id'] = df_predictions_1['image_id'].astype(str)\n",
    "\n",
    "# Rename bounding box columns in both DataFrames to the same name\n",
    "df_labels2.rename(columns={'bounding_box_coordinates': 'bounding_box'}, inplace=True)\n",
    "\n",
    "# Try merging again\n",
    "df_merged = pd.merge(df_labels2, df_predictions_1, on=['image_id'], how='inner', suffixes=('_true', '_pred'))\n",
    "\n",
    "# Check the first few rows of the merged DataFrame\n",
    "print(df_merged.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      image_id  object_class_true    bounding_box_true object_class_pred  \\\n",
      "0       001372                0.0  (91, 191, 369, 323)                 0   \n",
      "1       001372                0.0  (91, 191, 369, 323)                 0   \n",
      "2       001372                0.0  (91, 191, 369, 323)                 0   \n",
      "3       001372                0.0  (91, 191, 369, 323)                 0   \n",
      "4       001372                0.0  (91, 191, 369, 323)                 0   \n",
      "...        ...                ...                  ...               ...   \n",
      "33684   001359                0.0  (19, 201, 271, 301)                 2   \n",
      "33685   001359                0.0  (19, 201, 271, 301)                 2   \n",
      "33686   001359                0.0  (19, 201, 271, 301)                 2   \n",
      "33687   001359                0.0  (19, 201, 271, 301)                 2   \n",
      "33688   001359                0.0  (19, 201, 271, 301)                 2   \n",
      "\n",
      "        bounding_box_pred confidence_score  \n",
      "0        (18, -4, 19, -3)       0.78117496  \n",
      "1          (5, 20, 6, 21)       0.34733957  \n",
      "2        (47, -4, 48, -3)       0.23190214  \n",
      "3          (16, 8, 17, 9)       0.22101979  \n",
      "4        (14, -9, 15, -8)       0.16573866  \n",
      "...                   ...              ...  \n",
      "33684      (15, 5, 20, 7)       0.25083512  \n",
      "33685  (33, -12, 38, -11)        0.2403568  \n",
      "33686       (-1, 8, 1, 9)       0.23345874  \n",
      "33687      (30, 5, 34, 7)       0.23094864  \n",
      "33688      (35, 6, 39, 7)       0.22550206  \n",
      "\n",
      "[33689 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_id             0\n",
      "object_class_true    0\n",
      "bounding_box_true    0\n",
      "object_class_pred    0\n",
      "bounding_box_pred    0\n",
      "dtype: int64\n",
      "NaN in y_true: 0\n",
      "NaN in y_pred: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in the merged DataFrame\n",
    "print(df_merged.isna().sum())\n",
    "\n",
    "# Check if any NaN values are present in y_true or y_pred\n",
    "print(\"NaN in y_true:\", df_merged['object_class_true'].isna().sum())\n",
    "print(\"NaN in y_pred:\", df_merged['object_class_pred'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.46553751879069294\n",
      "Recall: 0.22624595565318056\n",
      "F1-Score: 0.28564660296210825\n"
     ]
    }
   ],
   "source": [
    "y_true = df_merged['object_class_true'].astype(int)\n",
    "y_pred = df_merged['object_class_pred'].astype(int)\n",
    "\n",
    "precision = precision_score(y_true, y_pred, average='weighted')\n",
    "recall = recall_score(y_true, y_pred, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intersection over Union (IoU) Calculation\n",
    "\n",
    "To compare the predicted and ground truth bounding boxes, we calculate the Intersection over Union (IoU) metric. The IoU measures how much the predicted bounding box overlaps with the ground truth bounding box.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  image_id  object_class_true object_class_pred  iou\n",
      "0   001372                0.0                 0  0.0\n",
      "1   001372                0.0                 0  0.0\n",
      "2   001372                0.0                 0  0.0\n",
      "3   001372                0.0                 0  0.0\n",
      "4   001372                0.0                 0  0.0\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate IoU for two bounding boxes\n",
    "def calculate_iou(box_true, box_pred):\n",
    "    x_min_true, y_min_true, x_max_true, y_max_true = box_true\n",
    "    x_min_pred, y_min_pred, x_max_pred, y_max_pred = box_pred\n",
    "\n",
    "    # Calculate intersection\n",
    "    x_min_inter = max(x_min_true, x_min_pred)\n",
    "    y_min_inter = max(y_min_true, y_min_pred)\n",
    "    x_max_inter = min(x_max_true, x_max_pred)\n",
    "    y_max_inter = min(y_max_true, y_max_pred)\n",
    "    \n",
    "    inter_area = max(0, x_max_inter - x_min_inter) * max(0, y_max_inter - y_min_inter)\n",
    "    \n",
    "    # Calculate areas of the two boxes\n",
    "    true_area = (x_max_true - x_min_true) * (y_max_true - y_min_true)\n",
    "    pred_area = (x_max_pred - x_min_pred) * (y_max_pred - y_min_pred)\n",
    "    \n",
    "    # Calculate IoU\n",
    "    iou = inter_area / float(true_area + pred_area - inter_area)\n",
    "    return iou\n",
    "\n",
    "# Add IoU calculations to the merged DataFrame\n",
    "df_merged['iou'] = df_merged.apply(lambda row: calculate_iou(row['bounding_box_true'], row['bounding_box_pred']), axis=1)\n",
    "\n",
    "# Print the first few entries with IoU values\n",
    "print(df_merged[['image_id', 'object_class_true', 'object_class_pred', 'iou']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC AUC score (Receiver Operating Characteristic - Area Under the Curve) \n",
    "\n",
    "The ROC AUC score evaluates the ability of a model to distinguish between classes by plotting the True Positive Rate (TPR or Recall) against the False Positive Rate (FPR) at different threshold levels.\n",
    "\n",
    "In the context of object detection, it can be computed for each class using the confidence scores of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score for class 0: 0.6232038267568941\n",
      "ROC AUC Score for class 1: 0.37072089871098945\n",
      "ROC AUC Score for class 2: 0.4412394296687697\n",
      "Macro-Averaged ROC AUC: 0.4783880517122177\n"
     ]
    }
   ],
   "source": [
    "# Convert object classes to binary labels for a \"one-vs-rest\" ROC AUC calculation\n",
    "class_name_to_label = {\n",
    "    'Car': 0, 'Pedestrian': 1, 'Cyclist': 2, \n",
    "    'Van': 0\n",
    "}\n",
    "\n",
    "# If you have confidence scores from predictions\n",
    "y_true = df_merged['object_class_true'].astype(int)\n",
    "y_pred_confidence = df_merged['confidence_score']  # Assuming this exists\n",
    "y_pred_label = df_merged['object_class_pred'].astype(int)\n",
    "\n",
    "# One-vs-rest ROC AUC for each class\n",
    "roc_auc_scores = {}\n",
    "for class_label in np.unique(y_true):\n",
    "    # Convert y_true and y_pred into binary labels (1 for class, 0 for others)\n",
    "    y_true_binary = (y_true == class_label).astype(int)\n",
    "    \n",
    "    # Compute the ROC AUC score for this class\n",
    "    try:\n",
    "        auc_score = roc_auc_score(y_true_binary, y_pred_confidence)\n",
    "        roc_auc_scores[class_label] = auc_score\n",
    "        print(f'ROC AUC Score for class {class_label}: {auc_score}')\n",
    "    except ValueError as e:\n",
    "        print(f'Could not calculate AUC for class {class_label}: {e}')\n",
    "\n",
    "# Overall (macro-average) ROC AUC\n",
    "macro_roc_auc = np.mean(list(roc_auc_scores.values()))\n",
    "print(f'Macro-Averaged ROC AUC: {macro_roc_auc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El código proporcionado demuestra un sólido enfoque para el procesamiento de datos de imágenes en tareas de detección de objetos. La elección de pandas para manejar los datos estructurados y la orientación hacia algoritmos de detección de objetos como Faster R-CNN o YOLO son decisiones acertadas. La capacidad de pandas para gestionar grandes conjuntos de datos y la eficiencia de estos algoritmos en tareas de visión por computadora hacen de esta combinación una solución efectiva para este tipo de problemas.\n",
    "Como equipo de data scientists, hemos analizado a fondo el código que nos has proporcionado. Nuestro primer acercamiento nos ha permitido identificar que este código se enfoca en la etapa inicial y fundamental de cualquier proyecto de detección de objetos: el preprocesamiento de datos.\n",
    "\n",
    "Hemos detectado que se utiliza Pandas para estructurar y manejar eficientemente la información de las imágenes y sus correspondientes etiquetas. Esta herramienta es ideal para este tipo de tareas, ya que nos permite crear DataFrames que facilitan la exploración y manipulación de los datos. Además, hemos identificado que se han sentado las bases para la visualización de los datos, aunque esta parte aún no está completamente implementada.\n",
    "\n",
    "Como equipo, hemos logrado un avance significativo al implementar un modelo preentrenado en el conjunto de datos KITTI. Sin embargo, al evaluar el modelo en un subconjunto de los datos de entrenamiento, hemos observado que la precisión aún no cumple con nuestras expectativas. Esto nos indica que hay margen de mejora y que debemos profundizar en nuestro análisis.\n",
    "\n",
    "Una de las principales limitantes que hemos identificado es la falta de evaluación en el conjunto de pruebas oficial de KITTI. Al no contar con las etiquetas correspondientes, no podemos obtener métricas precisas y comparables con otros modelos. A pesar de esta restricción, los resultados preliminares nos brindan una valiosa línea de base para futuras investigaciones.\n",
    "\n",
    "A partir de estos hallazgos, hemos definido los siguientes pasos:\n",
    "\n",
    "Evaluación en el conjunto de pruebas oficial: Tan pronto como tengamos acceso a las etiquetas del conjunto de pruebas, realizaremos una evaluación exhaustiva del modelo para obtener resultados más confiables.\n",
    "Exploración de diferentes arquitecturas: Investigaremos otras arquitecturas de redes neuronales convolucionales (CNN) que puedan ser más adecuadas para nuestra tarea.\n",
    "Ajuste de hiperparámetros: Experimentaremos con diferentes valores de hiperparámetros para optimizar el rendimiento del modelo.\n",
    "Aumento de datos: Consideraremos técnicas de aumento de datos para mejorar la generalización del modelo.\n",
    "Estamos convencidos de que al abordar estos puntos, podremos mejorar significativamente el rendimiento de nuestro modelo y obtener resultados más precisos en la detección de objetos en imágenes de KITTI. Esta experiencia nos ha permitido consolidar nuestros conocimientos en el área de visión por computadora y ha sentado las bases para futuros proyectos más ambiciosos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
